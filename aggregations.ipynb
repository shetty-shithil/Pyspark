{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a10dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a68b1661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/29 18:52:42 WARN Utils: Your hostname, Shithils-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.0.226 instead (on interface en0)\n",
      "25/11/29 18:52:42 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/29 18:52:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+----------+-----+---------+----+-----+------------+-------------+\n",
      "|Store|DayOfWeek|      Date|Sales|Customers|Open|Promo|StateHoliday|SchoolHoliday|\n",
      "+-----+---------+----------+-----+---------+----+-----+------------+-------------+\n",
      "|    1|        5|2015-07-31| 5263|      555|   1|    1|           0|            1|\n",
      "|    2|        5|2015-07-31| 6064|      625|   1|    1|           0|            1|\n",
      "|    3|        5|2015-07-31| 8314|      821|   1|    1|           0|            1|\n",
      "|    4|        5|2015-07-31|13995|     1498|   1|    1|           0|            1|\n",
      "|    5|        5|2015-07-31| 4822|      559|   1|    1|           0|            1|\n",
      "+-----+---------+----------+-----+---------+----+-----+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "aggSession = SparkSession.builder.appName(\"AggregationExample\").getOrCreate()\n",
    "df_agg=aggSession.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"train.csv\")\n",
    "df_agg.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc2c511",
   "metadata": {},
   "source": [
    "Spark is distributed, operations like distinct, join, groupby and repartition cause a shuffle which are expensive.\n",
    "Shuffling happens when data needs to be moved between executors (nodes) in a distributed cluster to be reorganized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc868ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------------------+----------+\n",
      "|Store|TotalSales|          AvgSales|CountSales|\n",
      "+-----+----------+------------------+----------+\n",
      "|  148|   6772949| 7189.967091295117|       942|\n",
      "|  463|   4747749| 5040.073248407643|       942|\n",
      "|  471|   4422266|  5834.12401055409|       758|\n",
      "|  496|   6059458| 6432.545647558386|       942|\n",
      "|  833|   4293342|4557.6878980891715|       942|\n",
      "| 1088|   3960984| 4204.866242038216|       942|\n",
      "|  243|   4407146| 5814.176781002639|       758|\n",
      "|  392|   5670675| 6019.824840764331|       942|\n",
      "|  540|   3513672| 4635.451187335092|       758|\n",
      "|  623|   5473895| 5810.928874734607|       942|\n",
      "+-----+----------+------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_agg.groupBy(\"Store\").agg(sum(\"Sales\").alias(\"TotalSales\"), avg(\"Sales\").alias(\"AvgSales\"), count(\"Sales\").alias(\"CountSales\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ed7f4",
   "metadata": {},
   "source": [
    "**Multi-Column GroupBy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07ede079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+----------+------------------+----------+\n",
      "|Store|DayofWeek|TotalSales|          AvgSales|CountSales|\n",
      "+-----+---------+----------+------------------+----------+\n",
      "|    1|        1|    662780| 4946.119402985075|       134|\n",
      "|    1|        2|    627874| 4650.918518518519|       135|\n",
      "|    1|        3|    601354| 4454.474074074074|       135|\n",
      "|    1|        4|    552772| 4094.607407407407|       135|\n",
      "|    1|        5|    609716| 4516.414814814815|       135|\n",
      "|    1|        6|    662358|4942.9701492537315|       134|\n",
      "|    1|        7|         0|               0.0|       134|\n",
      "|    2|        1|    775930| 5790.522388059701|       134|\n",
      "|    2|        2|    719473|  5329.42962962963|       135|\n",
      "|    2|        3|    770213| 5705.281481481482|       135|\n",
      "+-----+---------+----------+------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_agg.groupBy(\"Store\",\"DayofWeek\").agg(sum(\"Sales\").alias(\"TotalSales\"), avg(\"Sales\").alias(\"AvgSales\"), count(\"Sales\").alias(\"CountSales\")).orderBy(\"Store\",\"DayofWeek\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc2167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
